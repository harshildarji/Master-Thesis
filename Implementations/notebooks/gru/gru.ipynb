{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTdml_ZZO04W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('../')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jnlVHBXYGevQ",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from CustomRNN import DeepRNN\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnJ89dAtiljA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"darkgrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OQRUiZIIGevb"
      },
      "source": [
        "#### Import, shuffle and split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hc-jfPQDGevd",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('reber_sequences.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VZt1tuMDGevl",
        "colab": {}
      },
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9FVvyiR2Gevt",
        "colab": {}
      },
      "source": [
        "train_data = data[:int(.75*len(data))]\n",
        "test_data = data[len(train_data):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hFGa03AvGevx",
        "outputId": "53e891a3-2c9c-4fb8-ca54-fe0f2cfd0aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Total length: {}\\nTrain data length: {}\\nTest data length: {}'.format(len(data), len(train_data), len(test_data)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total length: 25000\n",
            "Train data length: 18750\n",
            "Test data length: 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uCoah1gRGev6"
      },
      "source": [
        "#### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6wDwJmInGev8",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30\n",
        "OUTPUT_SIZE = 2\n",
        "INPUT_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKtaST_DiqQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL = 'gru'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mETf9K_7GewC"
      },
      "source": [
        "#### Customize `Dataset` and create loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tvZNBTBqGewD",
        "colab": {}
      },
      "source": [
        "class MakeDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.strings = list(data['string'])\n",
        "        self.valid = list(data['valid'])\n",
        "        self.len = len(self.valid)\n",
        "        self.valid_list = [0, 1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.strings[index], self.valid[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qtRtnbUPGewI"
      },
      "source": [
        "Create train loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qIkc37iDGewJ",
        "colab": {}
      },
      "source": [
        "dataset = MakeDataset(train_data)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Onw5bwfjGewO"
      },
      "source": [
        "Create test loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8me9-GUdGewP",
        "colab": {}
      },
      "source": [
        "dataset = MakeDataset(test_data)\n",
        "test_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HiAzJtMSGewW"
      },
      "source": [
        "#### Some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VX5oPdsWGewX",
        "colab": {}
      },
      "source": [
        "def create_variable(tensor):\n",
        "    return Variable(tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rCKTIEbbGewh",
        "colab": {}
      },
      "source": [
        "def pad_seq(vect_seqs, seq_lens, valid):\n",
        "    seq_tensor = torch.zeros((len(vect_seqs), seq_lens.max())).long()\n",
        "    \n",
        "    for index, (seq, seq_len) in enumerate(zip(vect_seqs, seq_lens)):\n",
        "        seq_tensor[index, :seq_len] = torch.LongTensor(seq)\n",
        "        \n",
        "    return create_variable(seq_tensor), create_variable(seq_lens), create_variable(valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOeyEku_Gewn",
        "colab": {}
      },
      "source": [
        "def str2ascii(string):\n",
        "    ascii_arr = [ord(s) for s in string]\n",
        "    return ascii_arr, len(ascii_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g5HS0oTzGewq",
        "colab": {}
      },
      "source": [
        "def make_variables(strings, valid):\n",
        "    seqs_and_lens = [str2ascii(string)for string in strings]\n",
        "    vect_seqs = [s[0] for s in seqs_and_lens]\n",
        "    seq_lens = torch.LongTensor([s[1] for s in seqs_and_lens])\n",
        "    valid = torch.LongTensor(valid)\n",
        "    return pad_seq(vect_seqs, seq_lens, valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P1kyF1n6GexA"
      },
      "source": [
        "#### Define model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VKVStR_zDbs1",
        "colab": {}
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers : list):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_layers[0])\n",
        "        self.rnn = DeepRNN(hidden_layers[0], hidden_layers, mode='gru')\n",
        "        self.fc = nn.Linear(hidden_layers[-1], output_size)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        input = input.t()\n",
        "        embedded = self.embedding(input)\n",
        "\n",
        "        output, hiddens = self.rnn(embedded)\n",
        "\n",
        "        output = self.fc(output[-1])\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lQT4Qq2WGexR"
      },
      "source": [
        "#### Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRmp2k9KGexW",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, (string, valid) in enumerate(train_loader, 1):\n",
        "        input, seq_lens, target = make_variables(string, valid)\n",
        "\n",
        "        output = classifier(input)\n",
        "        \n",
        "        loss = criterion(output, target)\n",
        "        total_loss += loss.data.item()\n",
        "        \n",
        "        classifier.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('{}/{}\\tLoss: {:.5f}'.format(i * len(string), len(train_loader.dataset), total_loss / i * len(string)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zsOtVzFNGexe"
      },
      "source": [
        "#### Testing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ferW61amIjFP",
        "colab": {}
      },
      "source": [
        "test_acc = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EtDP_hJ0Gexh",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    correct = 0.\n",
        "    test_data_size = len(test_loader.dataset)\n",
        "    \n",
        "    for string, valid in test_loader:\n",
        "        input, seq_lens, target = make_variables(string, valid)\n",
        "\n",
        "        output = classifier(input)\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    acc = 100 * correct / test_data_size\n",
        "    test_acc.append(acc)\n",
        "        \n",
        "    print('\\nAccuracy: {:.2f}%\\n'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yudx6wVtGex2"
      },
      "source": [
        "#### Time for action!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e3jvvliDejlg"
      },
      "source": [
        "#### Base RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4emJ3S77Gex7",
        "colab": {}
      },
      "source": [
        "classifier = RNNModel(INPUT_SIZE, 2, [100, 100, 100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "10fUO7njcK06",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2az6-B2FGey3",
        "outputId": "c85563f6-ca2f-4ac8-a975-39be15df2ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    print('Epoch #{}\\n{}'.format(epoch, 12*'-'))\n",
        "    train()\n",
        "    test()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #1\n",
            "------------\n",
            "1600/18750\tLoss: 6.19143\n",
            "3200/18750\tLoss: 4.78378\n",
            "4800/18750\tLoss: 4.21246\n",
            "6400/18750\tLoss: 3.60892\n",
            "8000/18750\tLoss: 3.03486\n",
            "9600/18750\tLoss: 2.53725\n",
            "11200/18750\tLoss: 2.18732\n",
            "12800/18750\tLoss: 1.93580\n",
            "14400/18750\tLoss: 1.72285\n",
            "16000/18750\tLoss: 1.55103\n",
            "17600/18750\tLoss: 1.41057\n",
            "\n",
            "Accuracy: 99.94%\n",
            "\n",
            "Epoch #2\n",
            "------------\n",
            "1600/18750\tLoss: 0.00239\n",
            "3200/18750\tLoss: 0.00201\n",
            "4800/18750\tLoss: 0.00784\n",
            "6400/18750\tLoss: 0.05365\n",
            "8000/18750\tLoss: 0.05115\n",
            "9600/18750\tLoss: 0.04422\n",
            "11200/18750\tLoss: 0.04500\n",
            "12800/18750\tLoss: 0.08555\n",
            "14400/18750\tLoss: 0.07816\n",
            "16000/18750\tLoss: 0.07255\n",
            "17600/18750\tLoss: 0.06805\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #3\n",
            "------------\n",
            "1600/18750\tLoss: 0.00173\n",
            "3200/18750\tLoss: 0.00149\n",
            "4800/18750\tLoss: 0.00133\n",
            "6400/18750\tLoss: 0.00124\n",
            "8000/18750\tLoss: 0.00113\n",
            "9600/18750\tLoss: 0.00105\n",
            "11200/18750\tLoss: 0.00098\n",
            "12800/18750\tLoss: 0.00092\n",
            "14400/18750\tLoss: 0.00086\n",
            "16000/18750\tLoss: 0.00082\n",
            "17600/18750\tLoss: 0.00077\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #4\n",
            "------------\n",
            "1600/18750\tLoss: 0.00031\n",
            "3200/18750\tLoss: 0.00029\n",
            "4800/18750\tLoss: 0.00028\n",
            "6400/18750\tLoss: 0.00026\n",
            "8000/18750\tLoss: 0.00026\n",
            "9600/18750\tLoss: 0.00025\n",
            "11200/18750\tLoss: 0.00024\n",
            "12800/18750\tLoss: 0.00023\n",
            "14400/18750\tLoss: 0.00022\n",
            "16000/18750\tLoss: 0.00022\n",
            "17600/18750\tLoss: 0.00021\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #5\n",
            "------------\n",
            "1600/18750\tLoss: 0.00013\n",
            "3200/18750\tLoss: 0.00012\n",
            "4800/18750\tLoss: 0.00011\n",
            "6400/18750\tLoss: 0.00011\n",
            "8000/18750\tLoss: 0.00011\n",
            "9600/18750\tLoss: 0.00011\n",
            "11200/18750\tLoss: 0.00010\n",
            "12800/18750\tLoss: 0.00010\n",
            "14400/18750\tLoss: 0.00010\n",
            "16000/18750\tLoss: 0.00009\n",
            "17600/18750\tLoss: 0.00009\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #6\n",
            "------------\n",
            "1600/18750\tLoss: 0.00006\n",
            "3200/18750\tLoss: 0.00006\n",
            "4800/18750\tLoss: 0.00006\n",
            "6400/18750\tLoss: 0.00005\n",
            "8000/18750\tLoss: 0.00005\n",
            "9600/18750\tLoss: 0.00005\n",
            "11200/18750\tLoss: 0.00005\n",
            "12800/18750\tLoss: 0.00005\n",
            "14400/18750\tLoss: 0.00005\n",
            "16000/18750\tLoss: 0.00005\n",
            "17600/18750\tLoss: 0.00005\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #7\n",
            "------------\n",
            "1600/18750\tLoss: 0.00003\n",
            "3200/18750\tLoss: 0.00003\n",
            "4800/18750\tLoss: 0.00003\n",
            "6400/18750\tLoss: 0.00003\n",
            "8000/18750\tLoss: 0.00003\n",
            "9600/18750\tLoss: 0.00003\n",
            "11200/18750\tLoss: 0.00003\n",
            "12800/18750\tLoss: 0.00003\n",
            "14400/18750\tLoss: 0.00003\n",
            "16000/18750\tLoss: 0.00002\n",
            "17600/18750\tLoss: 0.00002\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #8\n",
            "------------\n",
            "1600/18750\tLoss: 0.00002\n",
            "3200/18750\tLoss: 0.00002\n",
            "4800/18750\tLoss: 0.00002\n",
            "6400/18750\tLoss: 0.00002\n",
            "8000/18750\tLoss: 0.00002\n",
            "9600/18750\tLoss: 0.00001\n",
            "11200/18750\tLoss: 0.00001\n",
            "12800/18750\tLoss: 0.00001\n",
            "14400/18750\tLoss: 0.00001\n",
            "16000/18750\tLoss: 0.00001\n",
            "17600/18750\tLoss: 0.00001\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #9\n",
            "------------\n",
            "1600/18750\tLoss: 0.00001\n",
            "3200/18750\tLoss: 0.00001\n",
            "4800/18750\tLoss: 0.00001\n",
            "6400/18750\tLoss: 0.00001\n",
            "8000/18750\tLoss: 0.00001\n",
            "9600/18750\tLoss: 0.00001\n",
            "11200/18750\tLoss: 0.00001\n",
            "12800/18750\tLoss: 0.00001\n",
            "14400/18750\tLoss: 0.00001\n",
            "16000/18750\tLoss: 0.00001\n",
            "17600/18750\tLoss: 0.00001\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #10\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #11\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #12\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #13\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #14\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #15\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #16\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #17\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #18\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #19\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #20\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #21\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #22\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #23\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #24\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #25\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #26\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #27\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #28\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #29\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #30\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "CPU times: user 31min 56s, sys: 32.7 s, total: 32min 29s\n",
            "Wall time: 32min 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBcNe-rQVAHg",
        "colab_type": "code",
        "outputId": "19b01fca-ecef-485a-9fea-398d80f5cc8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.title('{} Test Evaluation'.format(MODEL.upper()))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy %')\n",
        "plt.savefig('{}_accuracies.png'.format(MODEL.upper()))\n",
        "plt.plot(range(1, len(test_acc)+1), test_acc);"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFNCAYAAAB/vXevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdFairpCRiWk",
        "colab_type": "text"
      },
      "source": [
        "#### Save model and `state_dict` of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwmhF6IQWQVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('{}_accuracies.txt'.format(MODEL.upper()), 'a') as f:\n",
        "    f.write('{}'.format(MODEL.upper()) + ':' + ','.join(str(a.item()) for a in test_acc) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9lyRNkjRo66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classifier.state_dict(), './{}_state_dict.pt'.format(MODEL.upper()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEu0CimySHip",
        "colab_type": "code",
        "outputId": "c1c3996f-bf99-46f9-bd7e-64a7409b000a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "torch.save(classifier, './{}.pt'.format(MODEL.upper()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DeepRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRUCell. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}