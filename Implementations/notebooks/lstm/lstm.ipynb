{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTdml_ZZO04W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('../')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jnlVHBXYGevQ",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from CustomRNN import DeepRNN\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnJ89dAtiljA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"darkgrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OQRUiZIIGevb"
      },
      "source": [
        "#### Import, shuffle and split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hc-jfPQDGevd",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('reber_sequences.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VZt1tuMDGevl",
        "colab": {}
      },
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9FVvyiR2Gevt",
        "colab": {}
      },
      "source": [
        "train_data = data[:int(.75*len(data))]\n",
        "test_data = data[len(train_data):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hFGa03AvGevx",
        "outputId": "eb31fa36-eb75-4f2c-cf2b-c0ae44f9a446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Total length: {}\\nTrain data length: {}\\nTest data length: {}'.format(len(data), len(train_data), len(test_data)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total length: 25000\n",
            "Train data length: 18750\n",
            "Test data length: 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uCoah1gRGev6"
      },
      "source": [
        "#### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6wDwJmInGev8",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30\n",
        "OUTPUT_SIZE = 2\n",
        "INPUT_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKtaST_DiqQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL = 'lstm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mETf9K_7GewC"
      },
      "source": [
        "#### Customize `Dataset` and create loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tvZNBTBqGewD",
        "colab": {}
      },
      "source": [
        "class MakeDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.strings = list(data['string'])\n",
        "        self.valid = list(data['valid'])\n",
        "        self.len = len(self.valid)\n",
        "        self.valid_list = [0, 1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.strings[index], self.valid[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qtRtnbUPGewI"
      },
      "source": [
        "Create train loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qIkc37iDGewJ",
        "colab": {}
      },
      "source": [
        "dataset = MakeDataset(train_data)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Onw5bwfjGewO"
      },
      "source": [
        "Create test loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8me9-GUdGewP",
        "colab": {}
      },
      "source": [
        "dataset = MakeDataset(test_data)\n",
        "test_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HiAzJtMSGewW"
      },
      "source": [
        "#### Some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VX5oPdsWGewX",
        "colab": {}
      },
      "source": [
        "def create_variable(tensor):\n",
        "    return Variable(tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rCKTIEbbGewh",
        "colab": {}
      },
      "source": [
        "def pad_seq(vect_seqs, seq_lens, valid):\n",
        "    seq_tensor = torch.zeros((len(vect_seqs), seq_lens.max())).long()\n",
        "    \n",
        "    for index, (seq, seq_len) in enumerate(zip(vect_seqs, seq_lens)):\n",
        "        seq_tensor[index, :seq_len] = torch.LongTensor(seq)\n",
        "        \n",
        "    return create_variable(seq_tensor), create_variable(seq_lens), create_variable(valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOeyEku_Gewn",
        "colab": {}
      },
      "source": [
        "def str2ascii(string):\n",
        "    ascii_arr = [ord(s) for s in string]\n",
        "    return ascii_arr, len(ascii_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g5HS0oTzGewq",
        "colab": {}
      },
      "source": [
        "def make_variables(strings, valid):\n",
        "    seqs_and_lens = [str2ascii(string)for string in strings]\n",
        "    vect_seqs = [s[0] for s in seqs_and_lens]\n",
        "    seq_lens = torch.LongTensor([s[1] for s in seqs_and_lens])\n",
        "    valid = torch.LongTensor(valid)\n",
        "    return pad_seq(vect_seqs, seq_lens, valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P1kyF1n6GexA"
      },
      "source": [
        "#### Define model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VKVStR_zDbs1",
        "colab": {}
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers : list):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_layers[0])\n",
        "        self.rnn = DeepRNN(hidden_layers[0], hidden_layers, mode='lstm')\n",
        "        self.fc = nn.Linear(hidden_layers[-1], output_size)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        input = input.t()\n",
        "        embedded = self.embedding(input)\n",
        "\n",
        "        output, hiddens = self.rnn(embedded)\n",
        "\n",
        "        output = self.fc(output[-1])\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lQT4Qq2WGexR"
      },
      "source": [
        "#### Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRmp2k9KGexW",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, (string, valid) in enumerate(train_loader, 1):\n",
        "        input, seq_lens, target = make_variables(string, valid)\n",
        "\n",
        "        output = classifier(input)\n",
        "        \n",
        "        loss = criterion(output, target)\n",
        "        total_loss += loss.data.item()\n",
        "        \n",
        "        classifier.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('{}/{}\\tLoss: {:.5f}'.format(i * len(string), len(train_loader.dataset), total_loss / i * len(string)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zsOtVzFNGexe"
      },
      "source": [
        "#### Testing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ferW61amIjFP",
        "colab": {}
      },
      "source": [
        "test_acc = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EtDP_hJ0Gexh",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    correct = 0.\n",
        "    test_data_size = len(test_loader.dataset)\n",
        "    \n",
        "    for string, valid in test_loader:\n",
        "        input, seq_lens, target = make_variables(string, valid)\n",
        "\n",
        "        output = classifier(input)\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    acc = 100 * correct / test_data_size\n",
        "    test_acc.append(acc)\n",
        "        \n",
        "    print('\\nAccuracy: {:.2f}%\\n'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yudx6wVtGex2"
      },
      "source": [
        "#### Time for action!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e3jvvliDejlg"
      },
      "source": [
        "#### Base RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4emJ3S77Gex7",
        "colab": {}
      },
      "source": [
        "classifier = RNNModel(INPUT_SIZE, 2, [100, 100, 100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "10fUO7njcK06",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2az6-B2FGey3",
        "outputId": "860b521c-f1fc-4d42-87fc-e3fa9cd31d71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    print('Epoch #{}\\n{}'.format(epoch, 12*'-'))\n",
        "    train()\n",
        "    test()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #1\n",
            "------------\n",
            "1600/18750\tLoss: 6.84215\n",
            "3200/18750\tLoss: 5.22083\n",
            "4800/18750\tLoss: 4.54836\n",
            "6400/18750\tLoss: 4.19193\n",
            "8000/18750\tLoss: 3.86605\n",
            "9600/18750\tLoss: 3.40945\n",
            "11200/18750\tLoss: 2.96861\n",
            "12800/18750\tLoss: 2.60730\n",
            "14400/18750\tLoss: 2.31788\n",
            "16000/18750\tLoss: 2.08643\n",
            "17600/18750\tLoss: 1.89765\n",
            "\n",
            "Accuracy: 99.98%\n",
            "\n",
            "Epoch #2\n",
            "------------\n",
            "1600/18750\tLoss: 0.00723\n",
            "3200/18750\tLoss: 0.01738\n",
            "4800/18750\tLoss: 0.01300\n",
            "6400/18750\tLoss: 0.13316\n",
            "8000/18750\tLoss: 0.14233\n",
            "9600/18750\tLoss: 0.15429\n",
            "11200/18750\tLoss: 0.13470\n",
            "12800/18750\tLoss: 0.12496\n",
            "14400/18750\tLoss: 0.11371\n",
            "16000/18750\tLoss: 0.10284\n",
            "17600/18750\tLoss: 0.09480\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #3\n",
            "------------\n",
            "1600/18750\tLoss: 0.00038\n",
            "3200/18750\tLoss: 0.00108\n",
            "4800/18750\tLoss: 0.00083\n",
            "6400/18750\tLoss: 0.00125\n",
            "8000/18750\tLoss: 0.00426\n",
            "9600/18750\tLoss: 0.00380\n",
            "11200/18750\tLoss: 0.00353\n",
            "12800/18750\tLoss: 0.00311\n",
            "14400/18750\tLoss: 0.00284\n",
            "16000/18750\tLoss: 0.00419\n",
            "17600/18750\tLoss: 0.00387\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #4\n",
            "------------\n",
            "1600/18750\tLoss: 0.00009\n",
            "3200/18750\tLoss: 0.00009\n",
            "4800/18750\tLoss: 0.00023\n",
            "6400/18750\tLoss: 0.00018\n",
            "8000/18750\tLoss: 0.00016\n",
            "9600/18750\tLoss: 0.00014\n",
            "11200/18750\tLoss: 0.00013\n",
            "12800/18750\tLoss: 0.00012\n",
            "14400/18750\tLoss: 0.00011\n",
            "16000/18750\tLoss: 0.00011\n",
            "17600/18750\tLoss: 0.00010\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #5\n",
            "------------\n",
            "1600/18750\tLoss: 0.00004\n",
            "3200/18750\tLoss: 0.00003\n",
            "4800/18750\tLoss: 0.00003\n",
            "6400/18750\tLoss: 0.00003\n",
            "8000/18750\tLoss: 0.00003\n",
            "9600/18750\tLoss: 0.00004\n",
            "11200/18750\tLoss: 0.00004\n",
            "12800/18750\tLoss: 0.00011\n",
            "14400/18750\tLoss: 0.00010\n",
            "16000/18750\tLoss: 0.00010\n",
            "17600/18750\tLoss: 0.00009\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #6\n",
            "------------\n",
            "1600/18750\tLoss: 0.00002\n",
            "3200/18750\tLoss: 0.00002\n",
            "4800/18750\tLoss: 0.00002\n",
            "6400/18750\tLoss: 0.00002\n",
            "8000/18750\tLoss: 0.00002\n",
            "9600/18750\tLoss: 0.00002\n",
            "11200/18750\tLoss: 0.00001\n",
            "12800/18750\tLoss: 0.00001\n",
            "14400/18750\tLoss: 0.00001\n",
            "16000/18750\tLoss: 0.00001\n",
            "17600/18750\tLoss: 0.00001\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #7\n",
            "------------\n",
            "1600/18750\tLoss: 0.00001\n",
            "3200/18750\tLoss: 0.00001\n",
            "4800/18750\tLoss: 0.00001\n",
            "6400/18750\tLoss: 0.00001\n",
            "8000/18750\tLoss: 0.00001\n",
            "9600/18750\tLoss: 0.00001\n",
            "11200/18750\tLoss: 0.00001\n",
            "12800/18750\tLoss: 0.00001\n",
            "14400/18750\tLoss: 0.00001\n",
            "16000/18750\tLoss: 0.00001\n",
            "17600/18750\tLoss: 0.00001\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #8\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #9\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #10\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #11\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #12\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #13\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #14\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #15\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #16\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #17\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #18\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #19\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #20\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #21\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #22\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #23\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #24\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #25\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #26\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #27\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #28\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #29\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Epoch #30\n",
            "------------\n",
            "1600/18750\tLoss: 0.00000\n",
            "3200/18750\tLoss: 0.00000\n",
            "4800/18750\tLoss: 0.00000\n",
            "6400/18750\tLoss: 0.00000\n",
            "8000/18750\tLoss: 0.00000\n",
            "9600/18750\tLoss: 0.00000\n",
            "11200/18750\tLoss: 0.00000\n",
            "12800/18750\tLoss: 0.00000\n",
            "14400/18750\tLoss: 0.00000\n",
            "16000/18750\tLoss: 0.00000\n",
            "17600/18750\tLoss: 0.00000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "CPU times: user 1h 36min 38s, sys: 25.2 s, total: 1h 37min 3s\n",
            "Wall time: 1h 37min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBcNe-rQVAHg",
        "colab_type": "code",
        "outputId": "bf41350d-9a00-4405-e8fe-abdb448d3b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.title('{} Test Evaluation'.format(MODEL.upper()))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy %')\n",
        "plt.savefig('{}_accuracies.png'.format(MODEL.upper()))\n",
        "plt.plot(range(1, EPOCHS+1), test_acc);"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAFNCAYAAAB7SKeSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdFairpCRiWk",
        "colab_type": "text"
      },
      "source": [
        "#### Save model and `state_dict` of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwmhF6IQWQVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('{}_accuracies.txt'.format(MODEL.upper()), 'a') as f:\n",
        "    f.write('{}'.format(MODEL.upper()) + ':' + ','.join(str(a.item()) for a in test_acc) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9lyRNkjRo66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classifier.state_dict(), './{}_state_dict.pt'.format(MODEL.upper()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEu0CimySHip",
        "colab_type": "code",
        "outputId": "00387da0-ffad-406f-fa88-8c5ee9835b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "torch.save(classifier, './{}.pt'.format(MODEL.upper()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DeepRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTMCell. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}