{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTdml_ZZO04W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('../')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jnlVHBXYGevQ",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from CustomRNN import DeepRNN\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnJ89dAtiljA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"darkgrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OQRUiZIIGevb"
      },
      "source": [
        "#### Import, shuffle and split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hc-jfPQDGevd",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('reber_sequences.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VZt1tuMDGevl",
        "colab": {}
      },
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9FVvyiR2Gevt",
        "colab": {}
      },
      "source": [
        "train_data = data[:int(.75*len(data))]\n",
        "test_data = data[len(train_data):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hFGa03AvGevx",
        "outputId": "9dbbe44e-9dcd-4c80-82d2-5463561aa256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Total length: {}\\nTrain data length: {}\\nTest data length: {}'.format(len(data), len(train_data), len(test_data)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total length: 25000\n",
            "Train data length: 18750\n",
            "Test data length: 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uCoah1gRGev6"
      },
      "source": [
        "#### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6wDwJmInGev8",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30\n",
        "OUTPUT_SIZE = 2\n",
        "INPUT_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKtaST_DiqQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL = 'rnn-relu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mETf9K_7GewC"
      },
      "source": [
        "#### Customize `Dataset` and create loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tvZNBTBqGewD",
        "colab": {}
      },
      "source": [
        "class MakeDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.strings = list(data['string'])\n",
        "        self.valid = list(data['valid'])\n",
        "        self.len = len(self.valid)\n",
        "        self.valid_list = [0, 1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.strings[index], self.valid[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qtRtnbUPGewI"
      },
      "source": [
        "Create train loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qIkc37iDGewJ",
        "colab": {}
      },
      "source": [
        "dataset = MakeDataset(train_data)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Onw5bwfjGewO"
      },
      "source": [
        "Create test loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8me9-GUdGewP",
        "colab": {}
      },
      "source": [
        "dataset = MakeDataset(test_data)\n",
        "test_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HiAzJtMSGewW"
      },
      "source": [
        "#### Some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VX5oPdsWGewX",
        "colab": {}
      },
      "source": [
        "def create_variable(tensor):\n",
        "    return Variable(tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rCKTIEbbGewh",
        "colab": {}
      },
      "source": [
        "def pad_seq(vect_seqs, seq_lens, valid):\n",
        "    seq_tensor = torch.zeros((len(vect_seqs), seq_lens.max())).long()\n",
        "    \n",
        "    for index, (seq, seq_len) in enumerate(zip(vect_seqs, seq_lens)):\n",
        "        seq_tensor[index, :seq_len] = torch.LongTensor(seq)\n",
        "        \n",
        "    return create_variable(seq_tensor), create_variable(seq_lens), create_variable(valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOeyEku_Gewn",
        "colab": {}
      },
      "source": [
        "def str2ascii(string):\n",
        "    ascii_arr = [ord(s) for s in string]\n",
        "    return ascii_arr, len(ascii_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g5HS0oTzGewq",
        "colab": {}
      },
      "source": [
        "def make_variables(strings, valid):\n",
        "    seqs_and_lens = [str2ascii(string)for string in strings]\n",
        "    vect_seqs = [s[0] for s in seqs_and_lens]\n",
        "    seq_lens = torch.LongTensor([s[1] for s in seqs_and_lens])\n",
        "    valid = torch.LongTensor(valid)\n",
        "    return pad_seq(vect_seqs, seq_lens, valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P1kyF1n6GexA"
      },
      "source": [
        "#### Define model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VKVStR_zDbs1",
        "colab": {}
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers : list):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_layers[0])\n",
        "        self.rnn = DeepRNN(hidden_layers[0], hidden_layers, mode='relu')\n",
        "        self.fc = nn.Linear(hidden_layers[-1], output_size)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        input = input.t()\n",
        "        embedded = self.embedding(input)\n",
        "\n",
        "        output, hiddens = self.rnn(embedded)\n",
        "\n",
        "        output = self.fc(output[-1])\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lQT4Qq2WGexR"
      },
      "source": [
        "#### Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRmp2k9KGexW",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, (string, valid) in enumerate(train_loader, 1):\n",
        "        input, seq_lens, target = make_variables(string, valid)\n",
        "\n",
        "        output = classifier(input)\n",
        "        \n",
        "        loss = criterion(output, target)\n",
        "        total_loss += loss.data.item()\n",
        "        \n",
        "        classifier.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('{}/{}\\tLoss: {:.5f}'.format(i * len(string), len(train_loader.dataset), total_loss / i * len(string)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zsOtVzFNGexe"
      },
      "source": [
        "#### Testing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ferW61amIjFP",
        "colab": {}
      },
      "source": [
        "test_acc = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EtDP_hJ0Gexh",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    correct = 0.\n",
        "    test_data_size = len(test_loader.dataset)\n",
        "    \n",
        "    for string, valid in test_loader:\n",
        "        input, seq_lens, target = make_variables(string, valid)\n",
        "\n",
        "        output = classifier(input)\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    acc = 100 * correct / test_data_size\n",
        "    test_acc.append(acc)\n",
        "        \n",
        "    print('\\nAccuracy: {:.2f}%\\n'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yudx6wVtGex2"
      },
      "source": [
        "#### Time for action!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e3jvvliDejlg"
      },
      "source": [
        "#### Base RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4emJ3S77Gex7",
        "colab": {}
      },
      "source": [
        "classifier = RNNModel(INPUT_SIZE, 2, [100, 100, 100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "10fUO7njcK06",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2az6-B2FGey3",
        "outputId": "915b32fe-a9e1-41fc-8741-f64c0272d146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    print('Epoch #{}\\n{}'.format(epoch, 12*'-'))\n",
        "    train()\n",
        "    test()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #1\n",
            "------------\n",
            "1600/18750\tLoss: 10.28849\n",
            "3200/18750\tLoss: 7.36211\n",
            "4800/18750\tLoss: 8.37168\n",
            "6400/18750\tLoss: 7.09679\n",
            "8000/18750\tLoss: 6.25665\n",
            "9600/18750\tLoss: 5.68907\n",
            "11200/18750\tLoss: 5.31764\n",
            "12800/18750\tLoss: 5.03728\n",
            "14400/18750\tLoss: 4.81559\n",
            "16000/18750\tLoss: 4.64026\n",
            "17600/18750\tLoss: 4.47845\n",
            "\n",
            "Accuracy: 94.18%\n",
            "\n",
            "Epoch #2\n",
            "------------\n",
            "1600/18750\tLoss: 2.83132\n",
            "3200/18750\tLoss: 3.39134\n",
            "4800/18750\tLoss: 3.40795\n",
            "6400/18750\tLoss: 3.30381\n",
            "8000/18750\tLoss: 3.21927\n",
            "9600/18750\tLoss: 3.51987\n",
            "11200/18750\tLoss: 3.41984\n",
            "12800/18750\tLoss: 3.35950\n",
            "14400/18750\tLoss: 3.36211\n",
            "16000/18750\tLoss: 3.29519\n",
            "17600/18750\tLoss: 3.26739\n",
            "\n",
            "Accuracy: 94.06%\n",
            "\n",
            "Epoch #3\n",
            "------------\n",
            "1600/18750\tLoss: 2.84439\n",
            "3200/18750\tLoss: 2.85387\n",
            "4800/18750\tLoss: 2.86728\n",
            "6400/18750\tLoss: 2.93182\n",
            "8000/18750\tLoss: 2.92925\n",
            "9600/18750\tLoss: 2.83427\n",
            "11200/18750\tLoss: 2.87932\n",
            "12800/18750\tLoss: 3.04463\n",
            "14400/18750\tLoss: 3.00469\n",
            "16000/18750\tLoss: 3.00986\n",
            "17600/18750\tLoss: 2.98507\n",
            "\n",
            "Accuracy: 94.06%\n",
            "\n",
            "Epoch #4\n",
            "------------\n",
            "1600/18750\tLoss: 2.63574\n",
            "3200/18750\tLoss: 2.89375\n",
            "4800/18750\tLoss: 2.89230\n",
            "6400/18750\tLoss: 2.77071\n",
            "8000/18750\tLoss: 2.80461\n",
            "9600/18750\tLoss: 2.82019\n",
            "11200/18750\tLoss: 2.79309\n",
            "12800/18750\tLoss: 2.79869\n",
            "14400/18750\tLoss: 2.79962\n",
            "16000/18750\tLoss: 2.80685\n",
            "17600/18750\tLoss: 2.79719\n",
            "\n",
            "Accuracy: 94.16%\n",
            "\n",
            "Epoch #5\n",
            "------------\n",
            "1600/18750\tLoss: 2.68652\n",
            "3200/18750\tLoss: 2.68401\n",
            "4800/18750\tLoss: 2.66811\n",
            "6400/18750\tLoss: 2.73738\n",
            "8000/18750\tLoss: 2.74107\n",
            "9600/18750\tLoss: 2.73211\n",
            "11200/18750\tLoss: 2.73702\n",
            "12800/18750\tLoss: 2.72656\n",
            "14400/18750\tLoss: 2.74682\n",
            "16000/18750\tLoss: 2.74755\n",
            "17600/18750\tLoss: 19.13769\n",
            "\n",
            "Accuracy: 81.97%\n",
            "\n",
            "Epoch #6\n",
            "------------\n",
            "1600/18750\tLoss: 7.17566\n",
            "3200/18750\tLoss: 6.57745\n",
            "4800/18750\tLoss: 6.04287\n",
            "6400/18750\tLoss: 5.37025\n",
            "8000/18750\tLoss: 4.89334\n",
            "9600/18750\tLoss: 4.47868\n",
            "11200/18750\tLoss: 4.33294\n",
            "12800/18750\tLoss: 4.11395\n",
            "14400/18750\tLoss: 3.99387\n",
            "16000/18750\tLoss: 3.86494\n",
            "17600/18750\tLoss: 3.78970\n",
            "\n",
            "Accuracy: 94.13%\n",
            "\n",
            "Epoch #7\n",
            "------------\n",
            "1600/18750\tLoss: 2.58339\n",
            "3200/18750\tLoss: 2.60512\n",
            "4800/18750\tLoss: 2.67561\n",
            "6400/18750\tLoss: 2.72242\n",
            "8000/18750\tLoss: 2.78915\n",
            "9600/18750\tLoss: 2.81286\n",
            "11200/18750\tLoss: 2.81970\n",
            "12800/18750\tLoss: 2.84587\n",
            "14400/18750\tLoss: 2.80578\n",
            "16000/18750\tLoss: 2.78925\n",
            "17600/18750\tLoss: 2.79459\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #8\n",
            "------------\n",
            "1600/18750\tLoss: 2.82911\n",
            "3200/18750\tLoss: 2.67426\n",
            "4800/18750\tLoss: 2.62569\n",
            "6400/18750\tLoss: 2.70150\n",
            "8000/18750\tLoss: 2.68700\n",
            "9600/18750\tLoss: 2.71113\n",
            "11200/18750\tLoss: 2.71010\n",
            "12800/18750\tLoss: 2.73021\n",
            "14400/18750\tLoss: 2.74306\n",
            "16000/18750\tLoss: 2.74282\n",
            "17600/18750\tLoss: 2.76016\n",
            "\n",
            "Accuracy: 94.16%\n",
            "\n",
            "Epoch #9\n",
            "------------\n",
            "1600/18750\tLoss: 2.74300\n",
            "3200/18750\tLoss: 2.84192\n",
            "4800/18750\tLoss: 2.81429\n",
            "6400/18750\tLoss: 2.86353\n",
            "8000/18750\tLoss: 2.84661\n",
            "9600/18750\tLoss: 2.84013\n",
            "11200/18750\tLoss: 2.86770\n",
            "12800/18750\tLoss: 2.84747\n",
            "14400/18750\tLoss: 2.78141\n",
            "16000/18750\tLoss: 3.04021\n",
            "17600/18750\tLoss: 3.02221\n",
            "\n",
            "Accuracy: 94.10%\n",
            "\n",
            "Epoch #10\n",
            "------------\n",
            "1600/18750\tLoss: 2.69915\n",
            "3200/18750\tLoss: 2.92034\n",
            "4800/18750\tLoss: 2.90710\n",
            "6400/18750\tLoss: 2.85444\n",
            "8000/18750\tLoss: 2.77171\n",
            "9600/18750\tLoss: 2.79865\n",
            "11200/18750\tLoss: 2.78497\n",
            "12800/18750\tLoss: 2.79738\n",
            "14400/18750\tLoss: 2.79981\n",
            "16000/18750\tLoss: 2.79294\n",
            "17600/18750\tLoss: 2.79473\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #11\n",
            "------------\n",
            "1600/18750\tLoss: 2.62742\n",
            "3200/18750\tLoss: 2.78922\n",
            "4800/18750\tLoss: 2.73662\n",
            "6400/18750\tLoss: 2.74911\n",
            "8000/18750\tLoss: 2.67245\n",
            "9600/18750\tLoss: 2.71402\n",
            "11200/18750\tLoss: 2.73214\n",
            "12800/18750\tLoss: 2.73562\n",
            "14400/18750\tLoss: 2.75372\n",
            "16000/18750\tLoss: 2.72202\n",
            "17600/18750\tLoss: 2.73821\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #12\n",
            "------------\n",
            "1600/18750\tLoss: 3.02398\n",
            "3200/18750\tLoss: 2.98077\n",
            "4800/18750\tLoss: 2.81056\n",
            "6400/18750\tLoss: 2.73631\n",
            "8000/18750\tLoss: 2.78630\n",
            "9600/18750\tLoss: 2.72380\n",
            "11200/18750\tLoss: 2.72285\n",
            "12800/18750\tLoss: 2.74010\n",
            "14400/18750\tLoss: 2.74311\n",
            "16000/18750\tLoss: 2.74412\n",
            "17600/18750\tLoss: 2.76394\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #13\n",
            "------------\n",
            "1600/18750\tLoss: 2.64991\n",
            "3200/18750\tLoss: 2.76224\n",
            "4800/18750\tLoss: 2.70515\n",
            "6400/18750\tLoss: 2.78588\n",
            "8000/18750\tLoss: 2.72523\n",
            "9600/18750\tLoss: 2.70054\n",
            "11200/18750\tLoss: 2.75043\n",
            "12800/18750\tLoss: 2.77196\n",
            "14400/18750\tLoss: 2.77301\n",
            "16000/18750\tLoss: 2.78823\n",
            "17600/18750\tLoss: 2.77137\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #14\n",
            "------------\n",
            "1600/18750\tLoss: 2.79250\n",
            "3200/18750\tLoss: 2.87920\n",
            "4800/18750\tLoss: 2.91322\n",
            "6400/18750\tLoss: 2.87888\n",
            "8000/18750\tLoss: 2.83511\n",
            "9600/18750\tLoss: 2.88128\n",
            "11200/18750\tLoss: 2.83549\n",
            "12800/18750\tLoss: 2.80718\n",
            "14400/18750\tLoss: 2.82640\n",
            "16000/18750\tLoss: 2.79253\n",
            "17600/18750\tLoss: 2.79039\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #15\n",
            "------------\n",
            "1600/18750\tLoss: 2.37072\n",
            "3200/18750\tLoss: 2.64181\n",
            "4800/18750\tLoss: 2.62057\n",
            "6400/18750\tLoss: 2.62246\n",
            "8000/18750\tLoss: 2.67454\n",
            "9600/18750\tLoss: 2.67774\n",
            "11200/18750\tLoss: 2.67183\n",
            "12800/18750\tLoss: 2.65857\n",
            "14400/18750\tLoss: 2.71384\n",
            "16000/18750\tLoss: 2.75368\n",
            "17600/18750\tLoss: 2.72257\n",
            "\n",
            "Accuracy: 94.05%\n",
            "\n",
            "Epoch #16\n",
            "------------\n",
            "1600/18750\tLoss: 2.66925\n",
            "3200/18750\tLoss: 134.21941\n",
            "4800/18750\tLoss: 90.42596\n",
            "6400/18750\tLoss: 68.53359\n",
            "8000/18750\tLoss: 55.41071\n",
            "9600/18750\tLoss: 46.65445\n",
            "11200/18750\tLoss: 40.38123\n",
            "12800/18750\tLoss: 35.67624\n",
            "14400/18750\tLoss: 32.05025\n",
            "16000/18750\tLoss: 29.13063\n",
            "17600/18750\tLoss: 26.71710\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #17\n",
            "------------\n",
            "1600/18750\tLoss: 2.86403\n",
            "3200/18750\tLoss: 2.91065\n",
            "4800/18750\tLoss: 2.89981\n",
            "6400/18750\tLoss: 2.92363\n",
            "8000/18750\tLoss: 2.82121\n",
            "9600/18750\tLoss: 2.94044\n",
            "11200/18750\tLoss: 2.91399\n",
            "12800/18750\tLoss: 2.91479\n",
            "14400/18750\tLoss: 2.89552\n",
            "16000/18750\tLoss: 2.86085\n",
            "17600/18750\tLoss: 2.83153\n",
            "\n",
            "Accuracy: 94.11%\n",
            "\n",
            "Epoch #18\n",
            "------------\n",
            "1600/18750\tLoss: 2.81426\n",
            "3200/18750\tLoss: 2.57867\n",
            "4800/18750\tLoss: 2.70726\n",
            "6400/18750\tLoss: 2.77010\n",
            "8000/18750\tLoss: 2.77707\n",
            "9600/18750\tLoss: 2.77172\n",
            "11200/18750\tLoss: 2.77610\n",
            "12800/18750\tLoss: 2.75942\n",
            "14400/18750\tLoss: 2.76492\n",
            "16000/18750\tLoss: 2.74991\n",
            "17600/18750\tLoss: 2.75504\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #19\n",
            "------------\n",
            "1600/18750\tLoss: 2.84586\n",
            "3200/18750\tLoss: 2.66905\n",
            "4800/18750\tLoss: 2.71370\n",
            "6400/18750\tLoss: 2.74612\n",
            "8000/18750\tLoss: 2.74805\n",
            "9600/18750\tLoss: 2.76759\n",
            "11200/18750\tLoss: 2.70643\n",
            "12800/18750\tLoss: 2.73527\n",
            "14400/18750\tLoss: 2.74549\n",
            "16000/18750\tLoss: 2.74695\n",
            "17600/18750\tLoss: 2.74983\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #20\n",
            "------------\n",
            "1600/18750\tLoss: 2.51895\n",
            "3200/18750\tLoss: 2.66443\n",
            "4800/18750\tLoss: 2.70169\n",
            "6400/18750\tLoss: 2.73175\n",
            "8000/18750\tLoss: 2.68348\n",
            "9600/18750\tLoss: 2.69201\n",
            "11200/18750\tLoss: 2.71312\n",
            "12800/18750\tLoss: 2.72232\n",
            "14400/18750\tLoss: 2.77447\n",
            "16000/18750\tLoss: 2.77219\n",
            "17600/18750\tLoss: 2.76055\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #21\n",
            "------------\n",
            "1600/18750\tLoss: 2.68198\n",
            "3200/18750\tLoss: 2.72284\n",
            "4800/18750\tLoss: 2.77545\n",
            "6400/18750\tLoss: 2.69231\n",
            "8000/18750\tLoss: 2.66422\n",
            "9600/18750\tLoss: 2.68439\n",
            "11200/18750\tLoss: 2.70244\n",
            "12800/18750\tLoss: 2.69574\n",
            "14400/18750\tLoss: 2.68564\n",
            "16000/18750\tLoss: 2.67826\n",
            "17600/18750\tLoss: 2.73135\n",
            "\n",
            "Accuracy: 94.14%\n",
            "\n",
            "Epoch #22\n",
            "------------\n",
            "1600/18750\tLoss: 2.71264\n",
            "3200/18750\tLoss: 2.70655\n",
            "4800/18750\tLoss: 2.74233\n",
            "6400/18750\tLoss: 14.38377\n",
            "8000/18750\tLoss: 12.11871\n",
            "9600/18750\tLoss: 10.57459\n",
            "11200/18750\tLoss: 340.22714\n",
            "12800/18750\tLoss: 298.56902\n",
            "14400/18750\tLoss: 265.77226\n",
            "16000/18750\tLoss: 239.50704\n",
            "17600/18750\tLoss: 217.98763\n",
            "\n",
            "Accuracy: 93.94%\n",
            "\n",
            "Epoch #23\n",
            "------------\n",
            "1600/18750\tLoss: 3.23334\n",
            "3200/18750\tLoss: 2.94443\n",
            "4800/18750\tLoss: 2.97867\n",
            "6400/18750\tLoss: 2.94582\n",
            "8000/18750\tLoss: 98.80099\n",
            "9600/18750\tLoss: 83.00425\n",
            "11200/18750\tLoss: 71.59590\n",
            "12800/18750\tLoss: 63.03940\n",
            "14400/18750\tLoss: 56.39748\n",
            "16000/18750\tLoss: 51.05807\n",
            "17600/18750\tLoss: 46.69772\n",
            "\n",
            "Accuracy: 93.74%\n",
            "\n",
            "Epoch #24\n",
            "------------\n",
            "1600/18750\tLoss: 2.76056\n",
            "3200/18750\tLoss: 2.76287\n",
            "4800/18750\tLoss: 2.74920\n",
            "6400/18750\tLoss: 2.69831\n",
            "8000/18750\tLoss: 3.09550\n",
            "9600/18750\tLoss: 3.06585\n",
            "11200/18750\tLoss: 3.03533\n",
            "12800/18750\tLoss: 3.05510\n",
            "14400/18750\tLoss: 3.04481\n",
            "16000/18750\tLoss: 3.06370\n",
            "17600/18750\tLoss: 3.03779\n",
            "\n",
            "Accuracy: 94.08%\n",
            "\n",
            "Epoch #25\n",
            "------------\n",
            "1600/18750\tLoss: 3.18171\n",
            "3200/18750\tLoss: 2.89962\n",
            "4800/18750\tLoss: 3.01270\n",
            "6400/18750\tLoss: 2.93817\n",
            "8000/18750\tLoss: 2.91062\n",
            "9600/18750\tLoss: 2.86411\n",
            "11200/18750\tLoss: 2.86990\n",
            "12800/18750\tLoss: 2.83793\n",
            "14400/18750\tLoss: 2.84659\n",
            "16000/18750\tLoss: 2.80145\n",
            "17600/18750\tLoss: 5.20895\n",
            "\n",
            "Accuracy: 91.95%\n",
            "\n",
            "Epoch #26\n",
            "------------\n",
            "1600/18750\tLoss: 3.07404\n",
            "3200/18750\tLoss: 3.04872\n",
            "4800/18750\tLoss: 3.07506\n",
            "6400/18750\tLoss: 3.00543\n",
            "8000/18750\tLoss: 2.98559\n",
            "9600/18750\tLoss: 2.93609\n",
            "11200/18750\tLoss: 2.83381\n",
            "12800/18750\tLoss: 2.75704\n",
            "14400/18750\tLoss: 2.71813\n",
            "16000/18750\tLoss: 2.67691\n",
            "17600/18750\tLoss: 2.64311\n",
            "\n",
            "Accuracy: 94.13%\n",
            "\n",
            "Epoch #27\n",
            "------------\n",
            "1600/18750\tLoss: 2.50567\n",
            "3200/18750\tLoss: 2.39169\n",
            "4800/18750\tLoss: 2.22952\n",
            "6400/18750\tLoss: 2.12576\n",
            "8000/18750\tLoss: 2.05880\n",
            "9600/18750\tLoss: 2.20128\n",
            "11200/18750\tLoss: 2.26138\n",
            "12800/18750\tLoss: 2.19591\n",
            "14400/18750\tLoss: 2.11676\n",
            "16000/18750\tLoss: 2.02294\n",
            "17600/18750\tLoss: 1.89713\n",
            "\n",
            "Accuracy: 99.70%\n",
            "\n",
            "Epoch #28\n",
            "------------\n",
            "1600/18750\tLoss: 0.22550\n",
            "3200/18750\tLoss: 0.54501\n",
            "4800/18750\tLoss: 1.15219\n",
            "6400/18750\tLoss: 1.10175\n",
            "8000/18750\tLoss: 0.92865\n",
            "9600/18750\tLoss: 0.78487\n",
            "11200/18750\tLoss: 0.72503\n",
            "12800/18750\tLoss: 0.66260\n",
            "14400/18750\tLoss: 0.60089\n",
            "16000/18750\tLoss: 0.54519\n",
            "17600/18750\tLoss: 0.51494\n",
            "\n",
            "Accuracy: 99.95%\n",
            "\n",
            "Epoch #29\n",
            "------------\n",
            "1600/18750\tLoss: 0.06404\n",
            "3200/18750\tLoss: 0.06781\n",
            "4800/18750\tLoss: 0.08038\n",
            "6400/18750\tLoss: 0.06242\n",
            "8000/18750\tLoss: 0.05122\n",
            "9600/18750\tLoss: 0.05104\n",
            "11200/18750\tLoss: 0.05018\n",
            "12800/18750\tLoss: 0.04926\n",
            "14400/18750\tLoss: 0.04409\n",
            "16000/18750\tLoss: 0.04420\n",
            "17600/18750\tLoss: 0.04525\n",
            "\n",
            "Accuracy: 99.92%\n",
            "\n",
            "Epoch #30\n",
            "------------\n",
            "1600/18750\tLoss: 0.03724\n",
            "3200/18750\tLoss: 0.92403\n",
            "4800/18750\tLoss: 0.62860\n",
            "6400/18750\tLoss: 1.48664\n",
            "8000/18750\tLoss: 1.47896\n",
            "9600/18750\tLoss: 1.28722\n",
            "11200/18750\tLoss: 1.11231\n",
            "12800/18750\tLoss: 0.98228\n",
            "14400/18750\tLoss: 0.87494\n",
            "16000/18750\tLoss: 0.78903\n",
            "17600/18750\tLoss: 0.78157\n",
            "\n",
            "Accuracy: 99.89%\n",
            "\n",
            "CPU times: user 22min 24s, sys: 23.7 s, total: 22min 48s\n",
            "Wall time: 22min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBcNe-rQVAHg",
        "colab_type": "code",
        "outputId": "1d67557f-74d2-4be6-dbe8-140d68a0254a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.title('{} Test Evaluation'.format(MODEL.upper()))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy %')\n",
        "plt.savefig('{}_accuracies.png'.format(MODEL.upper()))\n",
        "plt.plot(range(1, len(test_acc)+1), test_acc);"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAFNCAYAAADhMQ3+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdFairpCRiWk",
        "colab_type": "text"
      },
      "source": [
        "#### Save model and `state_dict` of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwmhF6IQWQVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('{}_accuracies.txt'.format(MODEL.upper()), 'a') as f:\n",
        "    f.write('{}'.format(MODEL.upper()) + ':' + ','.join(str(a.item()) for a in test_acc) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9lyRNkjRo66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classifier.state_dict(), './{}_state_dict.pt'.format(MODEL.upper()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEu0CimySHip",
        "colab_type": "code",
        "outputId": "e3fd69b8-64c1-4df0-8f3a-8a70e8e01846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "torch.save(classifier, './{}.pt'.format(MODEL.upper()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DeepRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNCell. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}