\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {4.1}{\ignorespaces A few examples of true and false Reber sequences}}{37}{table.caption.39}%
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {4.2}{\ignorespaces The number of true and false Reber sequences in our train-test set}}{38}{table.caption.41}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {5.1}{\ignorespaces Hyper-parameters used for training and evaluating the base model}}{43}{table.caption.49}%
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {5.2}{\ignorespaces Computing layer indexing of example DAG}}{49}{table.caption.56}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {6.1}{\ignorespaces Pearson correlation between test accuracy of RNN\_Tanh and different graph and recurrent network properties}}{69}{table.caption.88}%
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {6.2}{\ignorespaces Pearson correlation between test accuracy of RNN\_ReLU and different graph and recurrent network properties}}{70}{table.caption.90}%
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {6.3}{\ignorespaces Pearson correlation between test accuracy of LSTM and different graph and recurrent network properties}}{71}{table.caption.92}%
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {6.4}{\ignorespaces Pearson correlation between test accuracy of GRU and different graph and recurrent network properties}}{72}{table.caption.94}%
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {6.5}{\ignorespaces R-squared values from each regressor algorithm, for each RNN variant}}{73}{table.caption.95}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {B.1}{\ignorespaces RNN\_ReLU - Feature importance scores for the Random Forest regressor under different circumstances}}{79}{table.caption.98}%
\defcounter {refsection}{0}\relax 
\contentsline {table}{\numberline {B.2}{\ignorespaces GRU - Feature importance scores for the Random Forest regressor under different circumstances}}{80}{table.caption.99}%
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
